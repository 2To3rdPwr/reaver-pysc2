import gin.tf.external_configurables

SC2Env.step_mul = 8
SC2Env.spatial_dim = 16

tf.train.AdamOptimizer.learning_rate = 0.005

AdvantageActorCriticAgent.model_fn = @build_fully_conv
AdvantageActorCriticAgent.policy_cls = @SC2MultiPolicy

AdvantageActorCriticAgent.batch_sz = 32
AdvantageActorCriticAgent.traj_len = 16
AdvantageActorCriticAgent.gae_lambda = 0.0
AdvantageActorCriticAgent.clip_grads_norm = 1.0
AdvantageActorCriticAgent.bootstrap_terminals = False
AdvantageActorCriticAgent.normalize_advantages = False
AdvantageActorCriticAgent.optimizer = @tf.train.AdamOptimizer()

AdvantageActorCriticAgent.value_coef = 0.5
AdvantageActorCriticAgent.entropy_coef = 0.01

ProximalPolicyOptimizationAgent.value_coef = 0.5
ProximalPolicyOptimizationAgent.entropy_coef = 0.01
ProximalPolicyOptimizationAgent.minibatch_sz = 250